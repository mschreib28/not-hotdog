{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets pillow rich transformers evaluate accelerate torchvision scikit-learn numpy pytorch-lightning ipywidgets huggingface_hub --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n",
      "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
      "    Setting a new token will erase the existing one.\n",
      "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (osxkeychain).\n",
      "Your token has been saved to /Users/michael.schreiber/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import interpreter_login\n",
    "\n",
    "interpreter_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect(datasets.Image, help=True)\n",
    "food = load_dataset(\"food101\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food: Dataset({\n",
      "    features: ['image', 'label'],\n",
      "    num_rows: 75750\n",
      "})\n",
      "\n",
      "all labels: ['apple_pie', 'baby_back_ribs', 'baklava', 'beef_carpaccio', 'beef_tartare', 'beet_salad', 'beignets', 'bibimbap', 'bread_pudding', 'breakfast_burrito', 'bruschetta', 'caesar_salad', 'cannoli', 'caprese_salad', 'carrot_cake', 'ceviche', 'cheesecake', 'cheese_plate', 'chicken_curry', 'chicken_quesadilla', 'chicken_wings', 'chocolate_cake', 'chocolate_mousse', 'churros', 'clam_chowder', 'club_sandwich', 'crab_cakes', 'creme_brulee', 'croque_madame', 'cup_cakes', 'deviled_eggs', 'donuts', 'dumplings', 'edamame', 'eggs_benedict', 'escargots', 'falafel', 'filet_mignon', 'fish_and_chips', 'foie_gras', 'french_fries', 'french_onion_soup', 'french_toast', 'fried_calamari', 'fried_rice', 'frozen_yogurt', 'garlic_bread', 'gnocchi', 'greek_salad', 'grilled_cheese_sandwich', 'grilled_salmon', 'guacamole', 'gyoza', 'hamburger', 'hot_and_sour_soup', 'hot_dog', 'huevos_rancheros', 'hummus', 'ice_cream', 'lasagna', 'lobster_bisque', 'lobster_roll_sandwich', 'macaroni_and_cheese', 'macarons', 'miso_soup', 'mussels', 'nachos', 'omelette', 'onion_rings', 'oysters', 'pad_thai', 'paella', 'pancakes', 'panna_cotta', 'peking_duck', 'pho', 'pizza', 'pork_chop', 'poutine', 'prime_rib', 'pulled_pork_sandwich', 'ramen', 'ravioli', 'red_velvet_cake', 'risotto', 'samosa', 'sashimi', 'scallops', 'seaweed_salad', 'shrimp_and_grits', 'spaghetti_bolognese', 'spaghetti_carbonara', 'spring_rolls', 'steak', 'strawberry_shortcake', 'sushi', 'tacos', 'takoyaki', 'tiramisu', 'tuna_tartare', 'waffles']\n",
      "\n",
      "food[0]: {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x4201D70B0>, 'label': 6}\n",
      "Example label: 6\n",
      "Example image filename: <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x4201D5AC0>\n"
     ]
    }
   ],
   "source": [
    "print(f'food: {food}\\n')\n",
    "\n",
    "labels = food.features['label'].names\n",
    "first_label = food[0]['label']\n",
    "first_image = food[0]['image']\n",
    "print(f'all labels: {labels}\\n')\n",
    "print(f'food[0]: {food[0]}')\n",
    "print(f'Example label: {first_label}')\n",
    "print(f'Example image filename: {first_image}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hot_dog: Dataset({\n",
      "    features: ['image', 'label'],\n",
      "    num_rows: 750\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "hot_dog = food.filter(lambda x: x['label'] == 49)\n",
    "print(f'hot_dog: {hot_dog}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all hot dogs to have the label 0\n",
    "hot_dog = hot_dog.map(lambda x: {'image': x['image'], 'label': 0}, num_proc=8)\n",
    "# Set all other images to have the label 1\n",
    "not_hot_dog = food.filter(lambda x: x['label'] != 49, num_proc=8).map(lambda x: {'image': x['image'], 'label': 1}, num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the not_hot_dog dataset\n",
    "not_hot_dog = not_hot_dog.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some pizza to the not_hot_dog dataset\n",
    "pizza = food.filter(lambda x: x['label'] == 63, num_proc=8).map(lambda x: {'image': x['image'], 'label': 1}, num_proc=8)\n",
    "# Configure the percentage pizza to be added\n",
    "pizza = pizza.train_test_split(test_size=0.5)['train']\n",
    "\n",
    "# Now add the pizza to the not_hot_dog dataset\n",
    "not_hot_dog_with_pizza = datasets.concatenate_datasets([not_hot_dog, pizza])\n",
    "\n",
    "# re-shuffle the not_hot_dog_with_pizza dataset and set it to the non_hot_dog dataset\n",
    "not_hot_dog = not_hot_dog_with_pizza.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hot_dog: 750\n",
      "not_hot_dog (before): 75750\n",
      "not_hot_dog: 750\n"
     ]
    }
   ],
   "source": [
    "# Check pre and post filtering lengths\n",
    "print(f'hot_dog: {len(hot_dog)}')\n",
    "print(f'not_hot_dog (before): {len(not_hot_dog)}')\n",
    "not_hot_dog = not_hot_dog.select(range(len(hot_dog)))\n",
    "print(f'not_hot_dog: {len(not_hot_dog)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recombine datasets of hotdog and not_hot_dog\n",
    "all_food = datasets.concatenate_datasets([hot_dog, not_hot_dog])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_food: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 1200\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 300\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing\n",
    "all_food = all_food.train_test_split(test_size=0.2)\n",
    "print(f'all_food: {all_food}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "\n",
    "# Transfer learning to load the pre-trained google vit model\n",
    "checkpoint = \"google/vit-base-patch16-224-in21k\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n",
    "\n",
    "# Define the image transformations and normalization to prevent overfitting\n",
    "normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "size = (\n",
    "    image_processor.size[\"shortest_edge\"]\n",
    "    if \"shortest_edge\" in image_processor.size\n",
    "    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    ")\n",
    "_transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms(examples):\n",
    "    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
    "    del examples[\"image\"]\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the transformations to the dataset and save it to the original variable\n",
    "all_food = all_food.with_transform(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "# Define the data collator which will be used to batch the data\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "# Load the accuracy metric from the hub\n",
    "accuracy = evaluate.load('accuracy')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Create a function to compute the accuracy of the model\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_food: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 1200\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 300\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(f'all_food: {all_food}')\n",
    "\n",
    "# Provide a label to id and id to label mapping\n",
    "label_to_id = {\"hot_dog\": 0, \"not_hot_dog\": 1}\n",
    "id_to_label = {0: \"hot_dog\", 1: \"not_hot_dog\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add gradient boosting to detect edge cases\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# # Define the model\n",
    "# model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(all_food[\"train\"][\"pixel_values\"], all_food[\"train\"][\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_food: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 1200\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 300\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(f'all_food: {all_food}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    num_labels=2,\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael.schreiber/Projects/not-hotdog/.venv/lib/python3.12/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28c4b592b6d4d278d10bee71826acae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6999, 'grad_norm': 0.9236725568771362, 'learning_rate': 4.166666666666667e-06, 'epoch': 0.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f597af65e83e48fc9bab69ef49ceebdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6830431222915649, 'eval_accuracy': 0.6166666666666667, 'eval_runtime': 11.5518, 'eval_samples_per_second': 25.97, 'eval_steps_per_second': 1.645, 'epoch': 0.96}\n",
      "{'loss': 0.6815, 'grad_norm': 1.0281648635864258, 'learning_rate': 4.62962962962963e-06, 'epoch': 1.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20a1c8e5f854f3da6bf4e58302dca6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6534063816070557, 'eval_accuracy': 0.7133333333333334, 'eval_runtime': 11.4935, 'eval_samples_per_second': 26.102, 'eval_steps_per_second': 1.653, 'epoch': 2.0}\n",
      "{'loss': 0.6505, 'grad_norm': 0.9051032662391663, 'learning_rate': 4.166666666666667e-06, 'epoch': 2.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "225bf19431b2476d83d3929a3256d9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6296890377998352, 'eval_accuracy': 0.72, 'eval_runtime': 11.0955, 'eval_samples_per_second': 27.038, 'eval_steps_per_second': 1.712, 'epoch': 2.96}\n",
      "{'loss': 0.6274, 'grad_norm': 1.0089205503463745, 'learning_rate': 3.7037037037037037e-06, 'epoch': 3.2}\n",
      "{'loss': 0.613, 'grad_norm': 0.8708637952804565, 'learning_rate': 3.240740740740741e-06, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ad512cba524e24a9881a4d2de97ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6032102704048157, 'eval_accuracy': 0.7666666666666667, 'eval_runtime': 11.1982, 'eval_samples_per_second': 26.79, 'eval_steps_per_second': 1.697, 'epoch': 4.0}\n",
      "{'loss': 0.5935, 'grad_norm': 1.046048879623413, 'learning_rate': 2.7777777777777783e-06, 'epoch': 4.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a1160a8bb54737ac18d8e263fb4df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5850763916969299, 'eval_accuracy': 0.79, 'eval_runtime': 13.9234, 'eval_samples_per_second': 21.546, 'eval_steps_per_second': 1.365, 'epoch': 4.96}\n",
      "{'loss': 0.5805, 'grad_norm': 0.8641161918640137, 'learning_rate': 2.314814814814815e-06, 'epoch': 5.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a77da693e345a6bbe17ef4d826576a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5685244798660278, 'eval_accuracy': 0.8133333333333334, 'eval_runtime': 12.4622, 'eval_samples_per_second': 24.073, 'eval_steps_per_second': 1.525, 'epoch': 6.0}\n",
      "{'loss': 0.559, 'grad_norm': 0.9292294979095459, 'learning_rate': 1.8518518518518519e-06, 'epoch': 6.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "424a79eda442494d838c85d67df2784d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5546382665634155, 'eval_accuracy': 0.8533333333333334, 'eval_runtime': 13.6445, 'eval_samples_per_second': 21.987, 'eval_steps_per_second': 1.392, 'epoch': 6.96}\n",
      "{'loss': 0.5596, 'grad_norm': 0.8832235932350159, 'learning_rate': 1.3888888888888892e-06, 'epoch': 7.2}\n",
      "{'loss': 0.5524, 'grad_norm': 0.9021896719932556, 'learning_rate': 9.259259259259259e-07, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd79e2870cc462e97522eac4875e13d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5484529137611389, 'eval_accuracy': 0.8466666666666667, 'eval_runtime': 12.8302, 'eval_samples_per_second': 23.382, 'eval_steps_per_second': 1.481, 'epoch': 8.0}\n",
      "{'loss': 0.5432, 'grad_norm': 0.9815702438354492, 'learning_rate': 4.6296296296296297e-07, 'epoch': 8.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "941bfc3ee1434a608c2e4232c7b2f0fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5444304943084717, 'eval_accuracy': 0.8533333333333334, 'eval_runtime': 12.516, 'eval_samples_per_second': 23.969, 'eval_steps_per_second': 1.518, 'epoch': 8.96}\n",
      "{'loss': 0.5401, 'grad_norm': 0.9436311721801758, 'learning_rate': 0.0, 'epoch': 9.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aceba41662a492eb5919a8a4a96c446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5427874326705933, 'eval_accuracy': 0.85, 'eval_runtime': 12.7112, 'eval_samples_per_second': 23.601, 'eval_steps_per_second': 1.495, 'epoch': 9.6}\n",
      "{'train_runtime': 1482.7839, 'train_samples_per_second': 8.093, 'train_steps_per_second': 0.081, 'train_loss': 0.6000442981719971, 'epoch': 9.6}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=120, training_loss=0.6000442981719971, metrics={'train_runtime': 1482.7839, 'train_samples_per_second': 8.093, 'train_steps_per_second': 0.081, 'train_loss': 0.6000442981719971, 'epoch': 9.6})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"not_hotdog\",\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-6,\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=6,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=all_food[\"train\"],\n",
    "    eval_dataset=all_food[\"test\"],\n",
    "    tokenizer=image_processor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model!\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
